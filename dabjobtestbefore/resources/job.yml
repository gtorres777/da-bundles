# The main job for dab_project.
resources:
  jobs:
    GV2_Pipeline-job:
      name: GV2_Pipeline_DAB

      # schedule:
      #   # Run every day at 8:37 AM
      #   quartz_cron_expression: '44 37 8 * * ?'
      #   timezone_id: Europe/Amsterdam

      tasks:
        - task_key: notebook_task_email
          job_cluster_key: App_Launch_Feature_Engineering_cluster_${bundle.target}
          notebook_task:
            notebook_path: test/getemail
            source: GIT

        - task_key: notebook_task_hello
          job_cluster_key: Agg_ML_Email_Metrics_cluster_${bundle.target}
          notebook_task:
            notebook_path: test/gethi
            source: GIT

      job_clusters:
        - job_cluster_key: App_Launch_Feature_Engineering_cluster_${bundle.target}
          new_cluster:
            aws_attributes:
              "ebs_volume_type": "GENERAL_PURPOSE_SSD"
              "ebs_volume_count": 1
              "ebs_volume_size": 32
            custom_tags:
              bamazon:team: eds_data_science
              bamazon:app: engds
              bamazon:env: prod

            # cluster_log_conf:
            #   s3:
            #     destination: s3://dbxoverwatch-databricks-cluster-logs-${bundle.target}/logs
            #     region: us-east-1
            spark_version: 13.3.x-scala2.12
            # node_type_id: m4.large
            node_type_id: ${var.NODE_TYPE_ID}
            driver_node_type_id: ${var.DRIVER_NODE_TYPE_ID_APP_LAUNCH_FEATURE_ENGINEERING_CLUSTER}
            autoscale:
                min_workers: 1
                max_workers: 2

        - job_cluster_key: Agg_ML_Email_Metrics_cluster_${bundle.target}
          new_cluster:
            aws_attributes:
              "ebs_volume_type": "GENERAL_PURPOSE_SSD"
              "ebs_volume_count": 1
              "ebs_volume_size": 32
            custom_tags:
              bamazon:team: eds_data_science
              bamazon:app: engds
              bamazon:env: prod

            # cluster_log_conf:
            #   s3:
            #     destination: s3://dbxoverwatch-databricks-cluster-logs-${bundle.target}/logs
            #     region: us-east-1
            spark_version: 13.3.x-scala2.12
            # node_type_id: m4.large
            node_type_id: ${var.NODE_TYPE_ID}
            driver_node_type_id: ${var.DRIVER_NODE_TYPE_ID_AGG_ML_EMAIL_METRICS_CLUSTER}
            autoscale:
                min_workers: 1
                max_workers: 2
